{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2241aaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Drago\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchio as tio\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e968f2",
   "metadata": {},
   "source": [
    "### For Loop to Procces the Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75921941",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_root = 'dataset_blurred'\n",
    "source_root = 'dataset'\n",
    "if os.path.exists(target_root):\n",
    "    shutil.rmtree(target_root)\n",
    "os.makedirs(target_root)\n",
    "\n",
    "# Loop over subfolders\n",
    "for class_name in os.listdir(source_root):\n",
    "    class_path = os.path.join(source_root, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        # Create matching subfolder in target\n",
    "        target_class_path = os.path.join(target_root, class_name)\n",
    "        os.makedirs(target_class_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60527c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_root = 'dataset_noised'\n",
    "source_root = 'dataset'\n",
    "if os.path.exists(target_root):\n",
    "    shutil.rmtree(target_root)\n",
    "os.makedirs(target_root)\n",
    "\n",
    "# Loop over subfolders\n",
    "for class_name in os.listdir(source_root):\n",
    "    class_path = os.path.join(source_root, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        # Create matching subfolder in target\n",
    "        target_class_path = os.path.join(target_root, class_name)\n",
    "        os.makedirs(target_class_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f865d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_root = 'dataset_motioned'\n",
    "source_root = 'dataset'\n",
    "if os.path.exists(target_root):\n",
    "    shutil.rmtree(target_root)\n",
    "os.makedirs(target_root)\n",
    "\n",
    "# Loop over subfolders\n",
    "for class_name in os.listdir(source_root):\n",
    "    class_path = os.path.join(source_root, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        # Create matching subfolder in target\n",
    "        target_class_path = os.path.join(target_root, class_name)\n",
    "        os.makedirs(target_class_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af75fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_root = 'dataset_mixed'\n",
    "source_root = 'dataset'\n",
    "if os.path.exists(target_root):\n",
    "    shutil.rmtree(target_root)\n",
    "os.makedirs(target_root)\n",
    "\n",
    "# Loop over subfolders\n",
    "for class_name in os.listdir(source_root):\n",
    "    class_path = os.path.join(source_root, class_name)\n",
    "\n",
    "    if os.path.isdir(class_path):\n",
    "        # Create matching subfolder in target\n",
    "        target_class_path = os.path.join(target_root, class_name)\n",
    "        os.makedirs(target_class_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270cecf",
   "metadata": {},
   "source": [
    "### Blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc0d470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed glioma → dataset_blurred\\Training\\glioma\n",
      "Processed meningioma → dataset_blurred\\Training\\meningioma\n",
      "Processed notumor → dataset_blurred\\Training\\notumor\n",
      "Processed pituitary → dataset_blurred\\Training\\pituitary\n",
      "Processed glioma → dataset_blurred\\Testing\\glioma\n",
      "Processed meningioma → dataset_blurred\\Testing\\meningioma\n",
      "Processed notumor → dataset_blurred\\Testing\\notumor\n",
      "Processed pituitary → dataset_blurred\\Testing\\pituitary\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# 1. Define your composed transform\n",
    "blur = tio.RandomBlur(std=(0, 2), p=1.0)\n",
    "\n",
    "# 2. Base paths\n",
    "input_base  = 'dataset'\n",
    "output_base = 'dataset_blurred'\n",
    "\n",
    "# 3. Loop over splits and classes\n",
    "for split in ['Training', 'Testing']:\n",
    "    split_in  = os.path.join(input_base,  split)\n",
    "    split_out = os.path.join(output_base, split)\n",
    "    for class_name in os.listdir(split_in):\n",
    "        in_dir  = os.path.join(split_in,  class_name)\n",
    "        out_dir = os.path.join(split_out, class_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # 4. Loop over images in each class folder\n",
    "        for fname in os.listdir(in_dir):\n",
    "            if not fname.lower().endswith(('.jpg', '.png')):\n",
    "                continue\n",
    "\n",
    "            # --- load image ---\n",
    "            img = Image.open(os.path.join(in_dir, fname)).convert('L')\n",
    "            arr = np.array(img)\n",
    "\n",
    "            # --- wrap as a 1‐slice “volume” ---\n",
    "            tensor = torch.from_numpy(arr).unsqueeze(0).unsqueeze(-1).float()\n",
    "            affine = np.eye(4)\n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(tensor=tensor, affine=affine)\n",
    "            )\n",
    "\n",
    "            # --- apply transforms ---\n",
    "            out = blur(subject)\n",
    "\n",
    "            # --- extract back to 2D array ---\n",
    "            result = out.image.data.squeeze(0).squeeze(-1).numpy()\n",
    "            result_img = Image.fromarray(np.clip(result, 0, 255).astype(np.uint8))\n",
    "\n",
    "            # --- save ---\n",
    "            save_path = os.path.join(out_dir, fname)\n",
    "            result_img.save(save_path)\n",
    "\n",
    "        print(f\"Processed {class_name} → {out_dir}\")\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7619121c",
   "metadata": {},
   "source": [
    "### Noised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb96870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed glioma → dataset_noised\\Training\\glioma\n",
      "Processed meningioma → dataset_noised\\Training\\meningioma\n",
      "Processed notumor → dataset_noised\\Training\\notumor\n",
      "Processed pituitary → dataset_noised\\Training\\pituitary\n",
      "Processed glioma → dataset_noised\\Testing\\glioma\n",
      "Processed meningioma → dataset_noised\\Testing\\meningioma\n",
      "Processed notumor → dataset_noised\\Testing\\notumor\n",
      "Processed pituitary → dataset_noised\\Testing\\pituitary\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# 1. Define your composed transform\n",
    "noise = tio.RandomNoise(mean=0, std=(0, 25), p=1.0)\n",
    "\n",
    "# 2. Base paths\n",
    "input_base  = 'dataset'\n",
    "output_base = 'dataset_noised'\n",
    "\n",
    "# 3. Loop over splits and classes\n",
    "for split in ['Training', 'Testing']:\n",
    "    split_in  = os.path.join(input_base,  split)\n",
    "    split_out = os.path.join(output_base, split)\n",
    "    for class_name in os.listdir(split_in):\n",
    "        in_dir  = os.path.join(split_in,  class_name)\n",
    "        out_dir = os.path.join(split_out, class_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # 4. Loop over images in each class folder\n",
    "        for fname in os.listdir(in_dir):\n",
    "            if not fname.lower().endswith(('.jpg', '.png')):\n",
    "                continue\n",
    "\n",
    "            # --- load image ---\n",
    "            img = Image.open(os.path.join(in_dir, fname)).convert('L')\n",
    "            arr = np.array(img)\n",
    "\n",
    "            # --- wrap as a 1‐slice “volume” ---\n",
    "            tensor = torch.from_numpy(arr).unsqueeze(0).unsqueeze(-1).float()\n",
    "            affine = np.eye(4)\n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(tensor=tensor, affine=affine)\n",
    "            )\n",
    "\n",
    "            # --- apply transforms ---\n",
    "            out = noise(subject)\n",
    "\n",
    "            # --- extract back to 2D array ---\n",
    "            result = out.image.data.squeeze(0).squeeze(-1).numpy()\n",
    "            result_img = Image.fromarray(np.clip(result, 0, 255).astype(np.uint8))\n",
    "\n",
    "            # --- save ---\n",
    "            save_path = os.path.join(out_dir, fname)\n",
    "            result_img.save(save_path)\n",
    "\n",
    "        print(f\"Processed {class_name} → {out_dir}\")\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17ab2bd",
   "metadata": {},
   "source": [
    "### Motioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4236e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed glioma → dataset_motioned\\Training\\glioma\n",
      "Processed meningioma → dataset_motioned\\Training\\meningioma\n",
      "Processed notumor → dataset_motioned\\Training\\notumor\n",
      "Processed pituitary → dataset_motioned\\Training\\pituitary\n",
      "Processed glioma → dataset_motioned\\Testing\\glioma\n",
      "Processed meningioma → dataset_motioned\\Testing\\meningioma\n",
      "Processed notumor → dataset_motioned\\Testing\\notumor\n",
      "Processed pituitary → dataset_motioned\\Testing\\pituitary\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# 1. Define your composed transform\n",
    "motion = tio.RandomMotion(\n",
    "    degrees=10,\n",
    "    translation=10,\n",
    "    num_transforms=2,\n",
    "    p=1.0,\n",
    ") \n",
    "\n",
    "# 2. Base paths\n",
    "input_base  = 'dataset'\n",
    "output_base = 'dataset_motioned'\n",
    "\n",
    "# 3. Loop over splits and classes\n",
    "for split in ['Training', 'Testing']:\n",
    "    split_in  = os.path.join(input_base,  split)\n",
    "    split_out = os.path.join(output_base, split)\n",
    "    for class_name in os.listdir(split_in):\n",
    "        in_dir  = os.path.join(split_in,  class_name)\n",
    "        out_dir = os.path.join(split_out, class_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # 4. Loop over images in each class folder\n",
    "        for fname in os.listdir(in_dir):\n",
    "            if not fname.lower().endswith(('.jpg', '.png')):\n",
    "                continue\n",
    "\n",
    "            # --- load image ---\n",
    "            img = Image.open(os.path.join(in_dir, fname)).convert('L')\n",
    "            arr = np.array(img)\n",
    "\n",
    "            # --- wrap as a 1‐slice “volume” ---\n",
    "            tensor = torch.from_numpy(arr).unsqueeze(0).unsqueeze(-1).float()\n",
    "            affine = np.eye(4)\n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(tensor=tensor, affine=affine)\n",
    "            )\n",
    "\n",
    "            # --- apply transforms ---\n",
    "            out = motion(subject)\n",
    "\n",
    "            # --- extract back to 2D array ---\n",
    "            result = out.image.data.squeeze(0).squeeze(-1).numpy()\n",
    "            result_img = Image.fromarray(np.clip(result, 0, 255).astype(np.uint8))\n",
    "\n",
    "            # --- save ---\n",
    "            save_path = os.path.join(out_dir, fname)\n",
    "            result_img.save(save_path)\n",
    "\n",
    "        print(f\"Processed {class_name} → {out_dir}\")\n",
    "\n",
    "print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1683ea75",
   "metadata": {},
   "source": [
    "### Mixed: Blurred - Noised - Motioned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e965d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed glioma → dataset_mixed\\Training\\glioma\n",
      "Processed meningioma → dataset_mixed\\Training\\meningioma\n",
      "Processed notumor → dataset_mixed\\Training\\notumor\n",
      "Processed pituitary → dataset_mixed\\Training\\pituitary\n",
      "Processed glioma → dataset_mixed\\Testing\\glioma\n",
      "Processed meningioma → dataset_mixed\\Testing\\meningioma\n",
      "Processed notumor → dataset_mixed\\Testing\\notumor\n",
      "Processed pituitary → dataset_mixed\\Testing\\pituitary\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "# 1. Define your composed transform\n",
    "transform = tio.Compose([\n",
    "    tio.RandomBlur( std=(0,2),    p=1.0 ),\n",
    "    tio.RandomNoise(mean=0, std=(0,25), p=1.0),\n",
    "    tio.RandomMotion(degrees=10, translation=10, num_transforms=2, p=1.0),\n",
    "])\n",
    "\n",
    "# 2. Base paths\n",
    "input_base  = 'dataset'\n",
    "output_base = 'dataset_mixed'\n",
    "\n",
    "# 3. Loop over splits and classes\n",
    "for split in ['Training', 'Testing']:\n",
    "    split_in  = os.path.join(input_base,  split)\n",
    "    split_out = os.path.join(output_base, split)\n",
    "    for class_name in os.listdir(split_in):\n",
    "        in_dir  = os.path.join(split_in,  class_name)\n",
    "        out_dir = os.path.join(split_out, class_name)\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # 4. Loop over images in each class folder\n",
    "        for fname in os.listdir(in_dir):\n",
    "            if not fname.lower().endswith(('.jpg', '.png')):\n",
    "                continue\n",
    "\n",
    "            # --- load image ---\n",
    "            img = Image.open(os.path.join(in_dir, fname)).convert('L')\n",
    "            arr = np.array(img)\n",
    "\n",
    "            # --- wrap as a 1‐slice “volume” ---\n",
    "            tensor = torch.from_numpy(arr).unsqueeze(0).unsqueeze(-1).float()\n",
    "            affine = np.eye(4)\n",
    "            subject = tio.Subject(\n",
    "                image=tio.ScalarImage(tensor=tensor, affine=affine)\n",
    "            )\n",
    "\n",
    "            # --- apply transforms ---\n",
    "            out = transform(subject)\n",
    "\n",
    "            # --- extract back to 2D array ---\n",
    "            result = out.image.data.squeeze(0).squeeze(-1).numpy()\n",
    "            result_img = Image.fromarray(np.clip(result, 0, 255).astype(np.uint8))\n",
    "\n",
    "            # --- save ---\n",
    "            save_path = os.path.join(out_dir, fname)\n",
    "            result_img.save(save_path)\n",
    "\n",
    "        print(f\"Processed {class_name} → {out_dir}\")\n",
    "\n",
    "print(\"All done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
